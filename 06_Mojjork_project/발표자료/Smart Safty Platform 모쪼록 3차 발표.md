# **모쪼록: 산업 현장 스마트 감지 플랫폼**

  

## **팀원 소개**

- **김세형**  → 전체 모델 설계, 학습, 추론 API 제작 및 데이터 수집 기획
    
- **강동주**  → Web/App UI 구성, 관리자용 대시보드 설계, 서버 연동 구현
    
- 박건준  → 현장 데이터 수집, 테스트용 영상 및 음성 가공
    

---

## **1. 기술 개요**

  

### **1.1 프로젝트 목적**

  

산업 현장에서 발생할 수 있는 **추락/낙상/충돌** 등 주요 재해 상황을 카메라 기반의 YOLO 객체 감지와

공사장 소음을 기반으로 한 **음성 위험 탐지 모델**을 통해 실시간 감지하여, 관리자와 작업자에게 경고를 전달하는 시스템입니다.

  

추후에는 **관리자용 대시보드**를 통해 작업자의 프로필, 위험 등급, 발생 로그 등을 **중앙 집중형**으로 관리할 수 있도록 확장합니다.

  

### **1.2 주요 기능**

- 실시간 영상 감지 (YOLOv8 기반 추락, 낙상, 충돌 등 감지)
    
- 음성 인식 모델로 비명, 충격음 등 위험 신호 탐지 (Wav2Vec 기반)
    
- BLE, GPS를 통한 위치 데이터 수집 및 경고 연동
    
- 관리자용 웹 대시보드 제공 (React + Spring 기반 예정)
    
- 실시간 알림 전달 (앱, 웹 푸시 또는 BLE 진동 경고)
    

  

### **1.3 해결 방식**

- 안전모에 장착 가능한 카메라 모듈 + 스마트폰 음성 수집 기능 활용
    
- YOLOv8n (Nano) 모델을 통해 Edge 추론도 가능하게 설계
    
- 음성 인식은 iOS 내장 마이크로 5초 단위 전송 + FastAPI 처리
    
- 감지 결과를 SQLite or Firebase 기반 서버 DB에 저장
    

---

## **2. 기술 스택**

  

### **모델 및 통신 스택**

- **YOLOv8n** : Edge 디바이스 기반 객체 감지
    
- **Wav2Vec 2.0 (Fine-tuned)** : 위험 음성 감지
    
- **FastAPI** : 실시간 영상 및 음성 감지 API 서버 구성
    
- **React / Next.js** : 관리자 대시보드 프론트엔드 구성
    
- **Spring / SQLite or Firebase** : 관리자 로그 서버 백엔드
    
- **BLE, GPS 모듈** : 작업자 위치 데이터 수집 및 통신 연동
    

---

## **3. 데이터 요구사항**

  

### **3.1 출처**

- 낙상/충돌 영상 : 자체 촬영 + 공공 데이터셋 일부
    
- 음성 위험음 : 인터넷 공개 DB + 공사 현장 수집 음성
    

  

### **3.2 전처리**

- YOLO용 객체 라벨링: fall, collision, trip, safe_zone, helmet, worker
    
- 음성 데이터: 위험음 vs 정상음 분류, 5초 단위 슬라이스
    

  

### **3.3 데이터셋 크기**

- 영상 약 2,000장 (라벨링 기준)
    
- 음성 약 30분 분량 (위험/정상 각 15분, 추가 수집 예정)
    

  

### **3.4 예외 처리**

- 음성 볼륨이 낮을 경우 무시, 또는 별도 미분류로 저장
    
- 라벨링이 불확실한 영상은 보류 데이터로 전환
    

---

## **4. 학습 및 결과 산출물**

  

### **4.1 모델 설계**

- YOLOv8n (input size=416), Epoch=100, mAP50 ~0.83
    
- Wav2Vec2 (pretrained from HuggingFace), Fine-tune Epoch=10
    

  

### **4.2 학습**

- YOLO는 분기점 형태의 낙상 시뮬레이션 영상으로 학습
    
- 음성은 사전 녹음된 비명, 충격음, 기계음 제거 샘플로 fine-tune
    

  

### **4.3 평가**

- YOLO: 낙상 검출 정확도 높음, 실시간 처리 가능
    
- 음성: 위험음 탐지 정확도는 ~87%, False Positive 보완 중
    

---

## **5. API 요구사항**

- POST /video-inference : 영상 프레임 이미지 전송 후 위험 객체 감지
    
- POST /audio-inference : 5초 음성 파일 업로드 후 위험 여부 판단
    
- WebSocket 채널 (추후): 양방향 실시간 통신용
    

---

## **6. 개선 방안**

- YOLO + 음성 결과 통합 판단 알고리즘 개발
    
- BLE + GPS기반 위치 연동 후 관리자 대시보드 시각화 연동
    
- 전반적인 통신 지연 감소를 위한 WebSocket 서버 도입 고려
    
- 프론트엔드: 위험 사용자 별 시각화 기능 및 상태 필터 구현 예정
    

---

## **7. 예시 형식 데이터**

| **입력 유형** | **감지 결과**                 | **요약**           | **응답/조치**                      |
| --------- | ------------------------- | ---------------- | ------------------------------ |
| 영상        | 낙상 감지 (fall), helmet 없음   | 낙상 감지 + 보호장구 미착용 | 관리자에게 알림 발송 + BLE 진동 전송        |
| 음성        | 충격음 + 비명                  | 위험도 상            | 긴급상황 인식, 위치 전송 + 실시간 관리자 확인 요청 |
| 영상+음성     | helmet 착용자, 낙상 없음, 기계음 감지 | 위험 없음            | 경고 없음, 기록 저장                   |