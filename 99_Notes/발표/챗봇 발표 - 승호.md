# í”„ë¡œì íŠ¸ ë°œí‘œ ê°œìš”

íŒ€ : 1ì¡°( ì´ëª…ìš©, ì„œì˜ê· , ì„œëª…ì§„, ë°•ì •ë¹ˆ, ê¹€ìŠ¹í˜¸)

í”„ë¡œì íŠ¸ ì„œì  ê³ ê° Q&A ì±—ë´‡ : ì„œëª…ì§„, ê¹€ìŠ¹í˜¸

# 1ì¥. í”„ë¡œì íŠ¸ ëª…

<aside> [í”„ë¡œì íŠ¸ëª…] ì„œì  ê³ ê° Q&A ì±—ë´‡

</aside>

# 2ì¥. í”„ë¡œì íŠ¸ ëª©í‘œ ë° ê¸°ëŠ¥

- ì£¼ìš” ëª©í‘œ: ì±… ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” **ìƒì„±í˜• AI ê¸°ë°˜ ê³ ê° ì‘ëŒ€ ëª¨ë¸** ê°œë°œ
- ì„¸ë¶€ ëª©í‘œ: ê¸°ì¡´ í”„ë¡œì íŠ¸(ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ)ì™€ ì°¨ë³„ì ì„ ë¶„ì„í•˜ì—¬ **ë” íš¨ê³¼ì ì¸ ì±… ê²€ìƒ‰ ë° ì •ë³´ ì œê³µ ë°©ì‹ êµ¬ì¶•**
- ì£¼ìš” ê¸°ëŠ¥

1ï¸âƒ£ **ì¼ë°˜ Q&A í•™ìŠµ ë°ì´í„° í•™ìŠµ ê°€ëŠ¥** â†’ ì§ˆë¬¸-ë‹µë³€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³ ê° ì‘ëŒ€ ê¸°ëŠ¥ ì œê³µ

2ï¸âƒ£ **ì±… ì •ë³´ë¥¼ ìë™ ìˆ˜ì§‘ ë° í•™ìŠµ ê°€ëŠ¥** â†’ ì¸í„°ë„· í¬ë¡¤ë§ì„ í™œìš©í•˜ì—¬ ìµœì‹  ì±… ì •ë³´ë¥¼ ë°˜ì˜

3ï¸âƒ£ **ê°„í¸í•œ ë°ì´í„° ê²€ìƒ‰ ë° ì‘ë‹µ ì‹œìŠ¤í…œ êµ¬ì¶•** â†’ ì‹¤ì‹œê°„ ì±„íŒ… ë°©ì‹ìœ¼ë¡œ ì›í•˜ëŠ” ì •ë³´ë¥¼ ë¹ ë¥´ê²Œ ì œê³µ

# 3ì¥. í”„ë¡œê·¸ë¨ ì§„í–‰ê³¼ì •

## 3.1 ê°œë°œ í™˜ê²½

```python
ì‚¬ìš© ì–¸ì–´: Python
ê°œë°œ ë„êµ¬: VSCode
ê¸°ìˆ  ìŠ¤íƒ: torch
```

## 3.2 ê°œë°œ ê³¼ì •

## 3.2.1 í•™ìŠµìš© QnA ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°

```python
# ë°ì´í„° ë¡œë“œ
df = pd.read_csv(r"C:\\HTMLHak\\proj2\\p2react\\backend\\fastapi\\app\\models\\data\\bookstore_chatbot_qa1_utf8.csv") #ì¼ë°˜ì ì¸ Q&A ì§ˆë‹µ ë°ì´í„°
book_df = pd.read_csv(r"C:\\HTMLHak\\proj2\\p2react\\backend\\fastapi\\app\\models\\data\\bestseller_data_cleaned.csv")

# ì§ˆë¬¸-ë‹µë³€ ê²°í•© ë° ì •ì œ
def clean_text(text):
    return re.sub(r"[^ê°€-í£a-zA-Z0-9\\s.,!?~]", "", str(text))
```

DBê´€ë¦¬ì™€ ìì—°ì–´ í•™ìŠµì„ ìœ„í•´ ë¶„ë¦¬

![ì‘ë‹µ ì˜¤ì—¼.png](attachment:b3eb5dbd-16dc-445d-9f1f-461d19d96ca0:%EC%9D%91%EB%8B%B5_%EC%98%A4%EC%97%BC.png)

## 3.2.2 ì¡°ì‚¬ ì œê±°

```python
def remove_particles(sentence):
    # ìì£¼ ì‚¬ìš©ë˜ëŠ” ì¡°ì‚¬ ë¦¬ìŠ¤íŠ¸
    particles = ["ì´", "ê°€", "ì€", "ëŠ”", "ì„", "ë¥¼", "ì—", "ì—ì„œ", "ì—ê²Œ", "ê»˜", "ë„", "ë§Œ", "ê³¼", "ì™€", "ë¡œ", "ìœ¼ë¡œ", "ë¶€í„°", "ê¹Œì§€", "ì˜", "ì—ê²Œì„œ"]
    for p in particles:
        sentence = re.sub(rf"\\b{p}\\b", "", sentence)  # ë„ì–´ì“°ê¸° ê¸°ì¤€ìœ¼ë¡œ ì¡°ì‚¬ ì œê±°
    return sentence.strip()
```

â€œì±… ì´ë¦„â€ì˜ ì‘ê°€ëŠ” ëˆ„êµ¬ì•¼? ê°™ì€ ì§ˆë¬¸ ì‘ë‹µì„±ì„ ë†’ì´ì§€ë§Œ í‚¤ì›Œë“œ ì¶”ì¶œë³´ë‹¤ ë¶ˆì•ˆí•˜ê³ ,

ì±… ì œëª©ì— í¬í•¨ëœ ì¡°ì‚¬ë„ í¬í•¨ë˜ì–´ í•™ìŠµì— ë¶ˆí¸í•¨ì´ ìˆìŒ

## 3.2.3 Dataset êµ¬ì„±

```python

class TextDataset(Dataset):
    def __init__(self, sequences, max_len=50):
        self.sequences = [s[:max_len] for s in sequences]
        self.max_len = max_len

    def __len__(self):
        return len(self.sequences)

    def __getitem__(self, idx):
        seq = self.sequences[idx]
        x = torch.tensor(seq[:-1], dtype=torch.long)
        y = torch.tensor(seq[1:], dtype=torch.long)
        return x, y  # ì…ë ¥ê³¼ íƒ€ê²Ÿì€ í•œ í† í° ì‹œí”„íŠ¸ë¨
dataset = TextDataset(encoded_data)
dataloader = DataLoader(dataset, batch_size=4, shuffle=True)

```

ì§ˆë¬¸ â†’ ë‹µë³€ , ì œëª©â†’ì‘ê°€â†’ë‚´ìš©â†’ì¥ë¥´ ìˆœì„œë¡œ í•™ìŠµ

## 3.2.4 ê¸¸ì´ ë³´ì •

```python

def collate_fn(batch):
    xs, ys = zip(*batch)  # ê° (x, y) ìŒ ë¶„ë¦¬
    xs = pad_sequence(xs, batch_first=True, padding_value=word2idx["<PAD>"])
    ys = pad_sequence(ys, batch_first=True, padding_value=word2idx["<PAD>"])
    return xs, ys

dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)

```

ì„œë¡œ ë‹¤ë¥¸ ì´ë¦„ì˜ ê¸¸ì´ë¥¼ ê°€ì§€ê³  ìˆì„ ë•Œ ì´ë¥¼ ë³´ì •

## 3.2.5 ì±… ì •ë³´ ê²€ìƒ‰

```python
# ì±… ì œëª©ì„ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜
def search_book(title):
    result = book_df[book_df["íƒ€ì´í‹€"].str.contains(title, na=False) | book_df["ë‚´ìš©"].str.contains(title, na=False)]
    return result if not result.empty else None

def search_book_info(title=None, author=None, genre=None, info_type=None):
    # ìš°ì„  ì±… ì œëª©ì´ ìˆë‹¤ë©´ ê·¸ê±¸ ê¸°ì¤€ìœ¼ë¡œ ê²€ìƒ‰
    if title is not None:
        row = book_df[book_df['íƒ€ì´í‹€'] == title]
        if not row.empty:
            row = row.iloc[0]
            if info_type == "ì‘ê°€":
                return row['ì‘ê°€']
            elif info_type == "ì¹´í…Œê³ ë¦¬":
                return row['ì¹´í…Œê³ ë¦¬']
            elif info_type == "ë‚´ìš©":
                return row['ë‚´ìš©']

            else:
                # ìš”ì²­ ì •ë³´ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ì ìœ¼ë¡œ ì±… ì œëª© ë°˜í™˜
                return title

    # ì œëª© ì—†ì„ ë•Œ ì‘ê°€ë‚˜ ì¥ë¥´ë¡œ ê²€ìƒ‰ (ê°„ë‹¨íˆ í•´ë‹¹ ì‘ê°€/ì¥ë¥´ ëª©ë¡ ë°˜í™˜)
    if info_type == "ì‘ê°€" and author is not None:
        books = book_df[book_df['ì‘ê°€'] == author]['íƒ€ì´í‹€'].tolist()
        return f"{author} ì‘ê°€ì˜ ì±… ëª©ë¡: {', '.join(books)}" if books else None
    if info_type == "ì¥ë¥´" and genre is not None:
        books = book_df[book_df['ì¹´í…Œê³ ë¦¬'] == genre]['íƒ€ì´í‹€'].tolist()
        return f"{genre} ì¥ë¥´ì˜ ì±… ëª©ë¡: {', '.join(books)}" if books else None

    return None
```

ì±…ì— ëŒ€í•œ ì •ë³´ë¥¼ ê²€ìƒ‰ ê°€ëŠ¥(ìµœìš°ì„  í•­ëª©ì€ ì œëª©)

## 3.2.6 ì±… ì •ë³´ ê²€ìƒ‰ ë‹µë³€

```python
def book_info_response(title=None, author=None, genre=None, info_type=None):
    info = search_book_info(title=title, author=author, genre=genre, info_type=info_type)
    if info:
        base = title or author or genre
        return f"ã€{base}ã€ì— ëŒ€í•œ {info_type} ì •ë³´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: {info}"
    else:
        return "í•´ë‹¹ ì±…ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
```

![ì§ˆì˜ì­ë‹µ.png](attachment:c2d93d43-5a95-42b3-b931-397494bd89df:%EC%A7%88%EC%9D%98%EC%9D%AD%EB%8B%B5.png)

ì±… ì •ë³´ ê´€ë ¨ ë‹µë³€

## 3.2.7 ê³ ê° ì‘ëŒ€ ë‹µë³€

```python
 
def generate_with_lstm(question, max_len=50, device='cpu'):
    model.eval()
    model.to(device)

    prompt = f"ì§ˆë¬¸: {question} ë‹µë³€:"
    input_ids = [word2idx.get("<BOS>")] + [word2idx.get(w, word2idx["<UNK>"]) for w in prompt.split()]
    input_tensor = torch.tensor([input_ids], dtype=torch.long).to(device)

    generated = input_ids.copy()
    for _ in range(max_len):
        with torch.no_grad():
            output = model(input_tensor)
        logits = output[0, -1]

        logits[word2idx["<UNK>"]] = -float('inf')
        logits[word2idx["<PAD>"]] = -float('inf')

        probs = torch.softmax(logits, dim=-1)
        next_token = torch.multinomial(probs, num_samples=1).item()

        generated.append(next_token)

        if next_token == word2idx["<EOS>"]:
            break

        input_tensor = torch.tensor([generated], dtype=torch.long).to(device)

    response_tokens = generated[len(input_ids):generated.index(word2idx["<EOS>"])] \\
        if word2idx["<EOS>"] in generated else generated[len(input_ids):]

    response = " ".join([idx2word.get(idx, "") for idx in response_tokens])
    return response.strip()

```

![ì§ˆì˜ì‘ë‹µ.png](attachment:c171a106-e224-4a84-b916-50673b23a2ef:%EC%A7%88%EC%9D%98%EC%9D%91%EB%8B%B5.png)

ê³ ê° ì‘ëŒ€ ë‹µë³€

## 3.2.8 ì§ˆë¬¸ ë‹µë³€

```python
def answer_question(model, question, max_len=50, device='cpu'):
    model.eval()
    model.to(device)

    # ì±… ì œëª© ë° ìš”ì²­ ì •ë³´ ì¶”ì¶œ + ì±… ì •ë³´ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    title, author, genre, info_type, has_book_info = extract_question_info(question)

    if has_book_info:
        return book_info_response(title, author, genre, info_type)  #  ì±… ì •ë³´ ì‘ë‹µ
    else:
        return generate_with_lstm(question)  #  ì¼ìƒ ëŒ€í™” ì‘ë‹µ
```

ì±—ë´‡ ë‹µë³€ ì‹œìŠ¤í…œ

## 3.3 ì‹œìŠ¤í…œ êµ¬ì¡°(ìµœì¢… êµ¬ì„±)

```mermaid
graph TD;
    A["ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥"] --> B["ì§ˆë¬¸ íƒ€ì… íŒë³„"];
    B --> C["ê³ ê° ì‘ëŒ€ ì§ˆë¬¸"];
    B --> D["ì±…ì— ê´€í•œ ì •ë³´"];
    C --> E["LSTM í•™ë°ì´í„° ê¸°ë°˜ ì‘ëŒ€"];
    D --> H["ë„ì„œ DB í•™ìŠµ ë°ì´í„° ì°¾ê¸°"];
    H --> F["ìµœì¢… ë‹µë³€"];
    E --> F;
    F --> G["ì‹œìŠ¤í…œ ì¢…ë£Œ"];
```

## 3.3.0 DB ë°ì´í„° ë³´ê°• í¬ë¡¤ë§

```python
# pip install selenium

import time
import requests
import os
import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException, TimeoutException

options = Options()

# options.add_argument("--headless")
user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"
options.add_argument(f"user-agent={user_agent}")
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
options.add_argument("--disable-blink-features=AutomationControlled")
options.add_argument("--disable-gpu")
options.add_argument("--window-size=1920,1080")
options.add_argument("--lang=ko-KR,ko")
options.add_experimental_option("excludeSwitches", ["enable-automation"])
options.add_experimental_option('useAutomationExtension', False)

driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
wait = WebDriverWait(driver, 10)
df = pd.read_csv("bestseller_data.csv")
os.makedirs('./download', exist_ok=True)

data_list = []

try:
    for index, row in df.iterrows():
        url = row["ë§í¬"]
        driver.get(url)
        time.sleep(3)

        try:
            try:
                xpath = '//*[@id="contents"]/div/div[1]/div[1]/div[1]/div[1]/div[1]/div/h1'
                title_element = wait.until(EC.presence_of_element_located((By.XPATH, xpath)))
                title = title_element.text.strip()
                print(title)
            except (NoSuchElementException, TimeoutException):
                title = ""

            try:
                xpath_s1 = '/html/body/div[3]/main/section[2]/div[1]/div/div[2]/div/div[3]/div[1]/div[2]/div/span[1]'
                discount_element = wait.until(EC.presence_of_element_located((By.XPATH, xpath_s1)))
                discount = discount_element.text.strip()
                print(discount)
            except (NoSuchElementException, TimeoutException):
                discount = ""

            try:
                xpath_price_discounted = '/html/body/div[3]/main/section[2]/div[1]/div/div[2]/div/div[3]/div[1]/div[2]/div/span[2]/span'
                price_discounted_element = driver.find_element(By.XPATH, xpath_price_discounted)
                price_discounted = price_discounted_element.text.strip()
                print(price_discounted)
            except NoSuchElementException:
                price_discounted = ""

            try:
                xpath_price_original = '/html/body/div[3]/main/section[2]/div[1]/div/div[2]/div/div[3]/div[1]/div[2]/div/span[3]/s'
                price_original_element = driver.find_element(By.XPATH, xpath_price_original)
                price_original = price_original_element.text.strip()
                print(price_original)
            except NoSuchElementException:
                price_original = ""

            # ìœ ë™ì ì¸ ì¹´í…Œê³ ë¦¬ XPath ì²˜ë¦¬
            category = ""
            try:
                base_xpath = '/html/body/div[3]/main/section[2]/div[2]/div[2]/div[1]/section[2]'
                category_lists = driver.find_elements(By.XPATH, f"{base_xpath}//ul/li/a[2]")
                if category_lists:
                    category = category_lists[0].text.strip()
                    print(category)
            except Exception:
                category = ""

            time.sleep(2)

        

            img_src = ""
            filename = ""

            try:
                xpath_img = '/html/body/div[3]/main/section[2]/div[1]/div/div[2]/div/div[2]/div[1]/div[1]/ul/li[1]/div/div[1]/img'
                img_element = driver.find_element(By.XPATH, xpath_img)
                img_src = img_element.get_attribute('src')
            except NoSuchElementException:
                pass

            if not img_src:
                try:
                    xpath_img = '/html/body/div[3]/main/section[2]/div[1]/div/div[2]/div[2]/div[2]/div[1]/div[1]/ul/li[1]/div/div[1]/img'
                    img_element = driver.find_element(By.XPATH, xpath_img)
                    img_src = img_element.get_attribute('src')
                except NoSuchElementException:
                    pass

            if img_src:
                response = requests.get(img_src)
                filename = os.path.basename(img_src)
                save_path = f'./download/{filename}'
                if response.status_code == 200:
                    with open(save_path, 'wb') as f:
                        f.write(response.content)
                    print("ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ:", save_path)
                else:
                    print("ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨:", response.status_code)

            time.sleep(0.1)
        except Exception as e:
            print(e)
            time.sleep(2)

        data_list.append({
            "ë§í¬": url,
            "íƒ€ì´í‹€": title,
            "í• ì¸ìœ¨": discount,
            "í• ì¸ëœ ê°€ê²©": price_discounted,
            "ì›ë³¸ ê°€ê²©": price_original,
            "ì¹´í…Œê³ ë¦¬": category,
            "ì´ë¯¸ì§€ URL": img_src,
            "ì´ë¯¸ì§€ íŒŒì¼ëª…": filename
        })
except Exception as e:
    print(f"Error : {e}")
finally:
    driver.quit()
    df1 = pd.DataFrame(data_list)
    df1.to_csv("bestseller_data_detail.csv", index=False, encoding='utf-8-sig')
    print("CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: bestseller_data_detail.csv")

```

## 3.3.1.1 ì±—ë´‡ í™”ë©´ êµ¬ì„± JavaScript

```jsx
// src/pages/ChatPage.js
import React, { useEffect, useRef, useState } from 'react';
import { Input, Button, List, Avatar, Typography } from 'antd';
import { SendOutlined, UserOutlined } from '@ant-design/icons';
import "../styles/ChatPage.css"
import ChatbotIcon from '../assets/chat_imote.png';
import axios from 'axios';

const { Text } = Typography;

const ChatPage = () => {
  const messagesListRef = useRef(null);
  const [messages, setMessages] = useState([
    { id: 1, sender: 'bot', text: 'ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?' },
  ]);
  const [input, setInput] = useState('');

  const handleSend = async () => {
    if (!input.trim()) return;
    const newMessage = { id: messages.length + 1, sender: 'user', text: input };
    const { data } = await axios.post('<http://localhost:8000/chat>', { question: input });
    setMessages([
      ...messages,
      newMessage,
      {
        id: messages.length + 2,
        sender: 'bot',
        text: data.response,
      },
    ]);
    setInput('');
  };

  useEffect(() => {
    if (messagesListRef.current) {
      messagesListRef.current.scrollIntoView({ behavior: 'smooth', block: 'end' });
    }
  }, [messages]);

  return (
    <div className="chat-page">
      <div className="chat-box">
        <div className="chat-header">
          <Text style={{ color: '#fff', fontSize: '20px' }}>ê³ ìš”í•œ ì±…ë°©</Text>
        </div>
        <div className="chat-content">
          <List
            dataSource={messages}
            renderItem={(item) => (
              <List.Item className={item.sender === 'user' ? 'chat-user' : 'chat-bot'}>
                <List.Item.Meta
                  avatar={<Avatar icon={<UserOutlined />} />}
                  title={item.sender === 'user' ? 'ë‚˜' : 'AIì‚¬ì„œ'}
                  description={item.text}
                />
              </List.Item>
            )}
          />
          <div ref={messagesListRef} />
        </div>
        <div className="chat-footer">
          <div className="chat-input-area">
            <Input
              value={input}
              onChange={(e) => setInput(e.target.value)}
              onPressEnter={handleSend}
              placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
              style={{ height: '40px', flexGrow: 1 }}
            />
            <Button
              type="primary"
              icon={<SendOutlined />}
              onClick={handleSend}
              style={{ height: '40px' }}
            />
          </div>
        </div>
      </div>
    </div>
  );
};

export default ChatPage;

```

## 3.3.1.2 í™”ë©´ êµ¬ì„± CSS

```css
/* src/pages/ChatPage.css */
.chat-page {
  display: flex;
  justify-content: center;
  align-items: center;
  height: 100vh;
  background-color: white;
}

.chat-box {
  width: 1000px;
  height: 900px;
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
  border-radius: 8px;
  background-color: #fff;
  display: flex;
  flex-direction: column;
  overflow: hidden;
}

.chat-header {
  background-color: #ffba18;
  display: flex;
  align-items: center;
  padding: 0 16px;
  height: 56px;
  font-size: 18px;
  color: #fff;
  font-weight: bold;
}

.chat-content {
  flex: 1;
  padding: 16px;
  overflow-y: auto;
  background-color: white;
}

.chat-footer {
  height: 64px;
  background-color: #f0f2f5;
  border-top: 1px solid #d9d9d9;
  box-sizing: border-box;
  padding: 12px 16px;
  flex-shrink: 0;
}

.chat-input-area {
  display: flex;
  align-items: center;
  width: 100%;
  height: 100%;
  gap: 8px;
}

.chat-user {
  display: flex;
  justify-content: flex-end;
}

.chat-user .ant-list-item-meta {
  display: flex;
  flex-direction: row-reverse;
  align-items: center;
  text-align: right;
}

.chat-user .ant-list-item-meta-avatar {
  margin-left: 8px;
}

.chat-user .ant-list-item-meta-description {
  background-color: #e6f4ff;
  border-radius: 12px;
  padding: 8px 12px;
  display: inline-block;
  max-width: 70%;
  word-break: break-word;
  text-align: left;
}

.chat-bot {
  justify-content: flex-start;
  display: flex;
  text-align: left
}

.chat-bot .ant-list-item-meta-description {
  background-color: #f5f5f5;
  border-radius: 8px;
  padding: 8px 12px;
  display: inline-block;
  max-width: 70%;
  text-align: left;
}

```

![ì±—ë´‡ í™”ë©´.png](attachment:c274abf2-22a6-4405-a621-21fd18394b6b:%EC%B1%97%EB%B4%87_%ED%99%94%EB%A9%B4.png)

â€˜ê³ ìš”í•œ ì±…ë°©â€™ ìœ¼ë¡œ ì¡°ìš©í•˜ê³  ê°œì¸ì ì¸ ê³µê°„ì´ ì—°ìƒë˜ë„ë¡ í•˜ì˜€ê³ 

ì±—ë´‡ì˜ ì´ë¦„ ì—­ì‹œ â€˜ì‚¬ì„œâ€™ë¡œ ì¼ë°˜ì ì¸ ìƒë‹´ì› ë³´ë‹¤ëŠ” ê°€ê¹ê²Œ ëŠê»´ì§€ë„ë¡ í•˜ì˜€ìŠµë‹ˆë‹¤.

## 3.3.2 React, FastAPI ì—°ë™

```jsx
import React from "react";
import ChatPage from "./pages/ChatPage";  // âœ… ChatPage ì»´í¬ë„ŒíŠ¸ ì¶”ê°€
import "./App.css";

function App() {
  return (
    <div className="App">
      <ChatPage />  {/* âœ… ChatPage ì»´í¬ë„ŒíŠ¸ ë Œë”ë§ */}
    </div>
  );
}

export default App;
```

```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from app.routers import chatbot_api  # chatbot_api.pyë¥¼ import

app = FastAPI()

# âœ… ğŸ”¹ CORS ì„¤ì • (Reactì—ì„œ API í˜¸ì¶œ ê°€ëŠ¥í•˜ê²Œ)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["<http://localhost:3000>"],  # Reactê°€ ì‹¤í–‰ë˜ëŠ” ì£¼ì†Œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# âœ… ğŸ”¹ FastAPI ì±—ë´‡ API ë“±ë¡
app.include_router(chatbot_api.router)

@app.get("/")
def read_root():
    return {"message": "FastAPI ì±—ë´‡ ì„œë²„ ì‹¤í–‰ ì¤‘!"}
```

## 3.3.3 ì£¼ìš” ì½”ë“œ(ëª¨ë¸êµ¬ì„±)

```python
class LSTMLanguageModel(nn.Module):
    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256, dropout=0.3):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, embed_dim)
        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)
        self.dropout = nn.Dropout(dropout)
        self.fc = nn.Linear(hidden_dim, vocab_size)

    def forward(self, x):
        x = self.embed(x)  # (B, T) â†’ (B, T, E)
        out, _ = self.lstm(x)  # (B, T, H)
        out = self.dropout(out)
        logits = self.fc(out)  # (B, T, V)
        return logits
model = LSTMLanguageModel(vocab_size, dropout=0.3) #ë“œë¡­ì•„ì›ƒ ì ìš©ìš©
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
criterion = nn.CrossEntropyLoss()
```

## 3.3.4 ì£¼ìš” ì½”ë“œ(ëª¨ë¸í•™ìŠµ)

```python
# í•™ìŠµ
for epoch in range(1000):
    model.train()
    total_loss = 0
    for x, y in dataloader:
        optimizer.zero_grad()
        logits = model(x)
        loss = criterion(logits.view(-1, vocab_size), y.view(-1))
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f"Epoch {epoch+1}, Loss: {total_loss:.4f}")
```

## 3.3.5 ì£¼ìš” ì½”ë“œ(ì„±ëŠ¥í‰ê°€)

```python
# í•™ìŠµ
for epoch in range(1000):
    model.train()
    total_loss = 0
    for x, y in dataloader:
        optimizer.zero_grad()
        logits = model(x)
        loss = criterion(logits.view(-1, vocab_size), y.view(-1))
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f"Epoch {epoch+1}, Loss: {total_loss:.4f}")
```

## 3.3.6 ì±—ë´‡ API

```python
import torch
import torch.nn as nn
import os
import re
from fastapi import APIRouter
from pydantic import BaseModel
import difflib
import pandas as pd
router = APIRouter()

# âœ… ì¡°ì‚¬ ì œê±° í•¨ìˆ˜
def remove_particles(sentence):
    particles = ["ì´", "ê°€", "ì€", "ëŠ”", "ì„", "ë¥¼", "ì—", "ì—ì„œ", "ì—ê²Œ", "ê»˜", "ë„", "ë§Œ", "ê³¼", "ì™€", "ë¡œ", "ìœ¼ë¡œ", "ë¶€í„°", "ê¹Œì§€", "ì˜", "ì—ê²Œì„œ"]
    for p in particles:
        sentence = re.sub(rf"\\b{p}\\b", "", sentence)
    return sentence.strip()

book_df = pd.read_csv(r"C:\\HTMLHak\\proj2\\p2react\\backend\\fastapi\\app\\models\\data\\bestseller_data_cleaned.csv")

# âœ… ê²½ë¡œ ì„¤ì • ë° ë‹¨ì–´ ì‚¬ì „ ë¡œë“œ
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
word2idx = torch.load(os.path.join(BASE_DIR, "../models/word2idx.pth"))
idx2word = {i: w for w, i in word2idx.items()}
vocab_size = len(word2idx)

def extract_question_info(question):
    title, author, genre, requested_info = None, None, None, None

    if not any(k in question for k in ["ì œëª©", "ì‘ê°€", "ì†Œì„¤", "ì¥ë¥´", "ë‚´ìš©", "ì¤„ê±°ë¦¬", "ì¹´í…Œê³ ë¦¬"]):
        # ì±… ê´€ë ¨ í‚¤ì›Œë“œ ì—†ìœ¼ë©´ ì•„ì˜ˆ ì‹œë„í•˜ì§€ ì•ŠìŒ
        return None, None, None, None, False

    # ì±… ì œëª© í›„ë³´ ì°¾ê¸°
    titles = book_df['íƒ€ì´í‹€'].tolist()
    title_matches = difflib.get_close_matches(question, titles, n=1, cutoff=0.7)
    if title_matches:
        title = title_matches[0]

    # ì‘ê°€ í›„ë³´ ì°¾ê¸°
    authors = book_df['ì‘ê°€'].unique().tolist()
    author_matches = difflib.get_close_matches(question, authors, n=1, cutoff=0.8)
    if author_matches:
        author = author_matches[0]

    # ì¹´í…Œê³ ë¦¬ í›„ë³´ ì°¾ê¸°
    genres = book_df['ì¹´í…Œê³ ë¦¬'].unique().tolist()
    genre_matches = difflib.get_close_matches(question, genres, n=1, cutoff=0.9)
    if genre_matches:
        genre = genre_matches[0]

    # ìš”ì²­ëœ ì •ë³´ íŒë‹¨
    # ì¤‘ë³µ í‚¤ì›Œë“œ ì œê±°
    if any(k in question for k in ["ì‘ê°€", "ì €ì"]):
        requested_info = "ì‘ê°€"
    elif any(k in question for k in ["ì¹´í…Œê³ ë¦¬", "ì¥ë¥´"]):
        requested_info = "ì¹´í…Œê³ ë¦¬"
    elif any(k in question for k in ["ì„¤ëª…", "ë‚´ìš©", "ì¤„ê±°ë¦¬"]):
        requested_info = "ë‚´ìš©"
    else:
        requested_info = None

    has_book_info = any([title, author, genre])
    return title, author, genre, requested_info, has_book_info

def search_book_info(title=None, author=None, genre=None, info_type=None):
    # ìš°ì„  ì±… ì œëª©ì´ ìˆë‹¤ë©´ ê·¸ê±¸ ê¸°ì¤€ìœ¼ë¡œ ê²€ìƒ‰
    if title is not None:
        row = book_df[book_df['íƒ€ì´í‹€'] == title]
        if not row.empty:
            row = row.iloc[0]
            if info_type == "ì‘ê°€":
                return row['ì‘ê°€']
            elif info_type == "ì¹´í…Œê³ ë¦¬":
                return row['ì¹´í…Œê³ ë¦¬']
            elif info_type == "ë‚´ìš©":
                return row['ë‚´ìš©']

            else:
                # ìš”ì²­ ì •ë³´ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ì ìœ¼ë¡œ ì±… ì œëª© ë°˜í™˜
                return title

    # ì œëª© ì—†ì„ ë•Œ ì‘ê°€ë‚˜ ì¥ë¥´ë¡œ ê²€ìƒ‰ (ê°„ë‹¨íˆ í•´ë‹¹ ì‘ê°€/ì¥ë¥´ ëª©ë¡ ë°˜í™˜)
    if info_type == "ì‘ê°€" and author is not None:
        books = book_df[book_df['ì‘ê°€'] == author]['íƒ€ì´í‹€'].tolist()
        return f"{author} ì‘ê°€ì˜ ì±… ëª©ë¡: {', '.join(books)}" if books else None
    if info_type == "ì¥ë¥´" and genre is not None:
        books = book_df[book_df['ì¹´í…Œê³ ë¦¬'] == genre]['íƒ€ì´í‹€'].tolist()
        return f"{genre} ì¥ë¥´ì˜ ì±… ëª©ë¡: {', '.join(books)}" if books else None
# âœ… LSTM ëª¨ë¸ ì •ì˜
class LSTMLanguageModel(nn.Module):
    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256, dropout=0.3):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, embed_dim)
        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)
        self.dropout = nn.Dropout(dropout)
        self.fc = nn.Linear(hidden_dim, vocab_size)

    def forward(self, x):
        x = self.embed(x)
        out, _ = self.lstm(x)
        out = self.dropout(out)
        return self.fc(out)

# âœ… ëª¨ë¸ ë¡œë“œ
model = LSTMLanguageModel(vocab_size)
model.load_state_dict(torch.load(os.path.join(BASE_DIR, "../models/chatbot_model.pth")))
model.eval()

def book_info_response(title=None, author=None, genre=None, info_type=None):
    info = search_book_info(title=title, author=author, genre=genre, info_type=info_type)
    if info:
        base = title or author or genre
        return f"ã€{base}ã€ì— ëŒ€í•œ {info_type} ì •ë³´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: {info}"
    else:
        return "í•´ë‹¹ ì±…ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    
def generate_with_lstm(question, max_len=50, device='cpu', min_len=3):
    model.eval()
    model.to(device)

    prompt = f"ì§ˆë¬¸: {question} ë‹µë³€:"
    input_ids = [word2idx.get("<BOS>")] + [word2idx.get(w, word2idx["<UNK>"]) for w in prompt.split()]
    input_tensor = torch.tensor([input_ids], dtype=torch.long).to(device)

    generated = input_ids.copy()
    for _ in range(max_len):
        with torch.no_grad():
            output = model(input_tensor)
        logits = output[0, -1]

        logits[word2idx["<UNK>"]] = -float('inf')
        logits[word2idx["<PAD>"]] = -float('inf')

        probs = torch.softmax(logits, dim=-1)
        next_token = torch.multinomial(probs, num_samples=1).item()

        generated.append(next_token)

        if next_token == word2idx["<EOS>"]:
            break

        input_tensor = torch.tensor([generated], dtype=torch.long).to(device)

    response_tokens = generated[len(input_ids):generated.index(word2idx["<EOS>"])] \\
        if word2idx["<EOS>"] in generated else generated[len(input_ids):]

    response = " ".join([idx2word.get(idx, "") for idx in response_tokens])
    return response.strip()

def answer_question(model, question, max_len=50, device='cpu'):
    model.eval()
    model.to(device)

    # ì±… ì œëª© ë° ìš”ì²­ ì •ë³´ ì¶”ì¶œ + ì±… ì •ë³´ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    title, author, genre, info_type, has_book_info = extract_question_info(question)

    if has_book_info:
        return book_info_response(title, author, genre, info_type)  #  ì±… ì •ë³´ ì‘ë‹µ
    else:
        return generate_with_lstm(question)  #  ì¼ìƒ ëŒ€í™” ì‘ë‹µ

# âœ… FastAPI ìš”ì²­ ëª¨ë¸
class QuestionRequest(BaseModel):
    question: str

@router.post("/chat")
def chat(request: QuestionRequest):
    clean_question = remove_particles(request.question)

    title, author, genre, info_type, has_book_info = extract_question_info(clean_question)

    if has_book_info:
        response = book_info_response(title, author, genre, info_type)
    else:
        response = generate_with_lstm(clean_question)
        if not response.strip():
            response = "âš ï¸ ì ì ˆí•œ ë‹µë³€ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    return {"question": clean_question, "response": response}
```

# 4ì¥. ê²°ê³¼

## 4.0 ì‚¬ì „ ë°ì´í„°

ë³¸ í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©ëœ ì‚¬ì „ ë°ì´í„°ì˜ íŠ¹ì„±ê³¼ ê·œëª¨ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

- ë°ì´í„° í¬ê¸°: 50ê°œì˜ ê³ ê° ë¬¸ì˜ ë°ì´í„° + í¬ë¡¤ë§ìœ¼ë¡œ ìˆ˜ì§‘í•œ ì±… 60ê°œ ë¶„ëŸ‰ ë°ì´í„°
- ë°ì´í„° í˜•ì‹: í…ìŠ¤íŠ¸ ê¸°ë°˜ Q&A ìŒ + ì±…ì— ëŒ€í•œ ì •ë³´(ì±… ì´ë¦„, ì‘ê°€, ë‚´ìš©, ì¥ë¥´ ë“±)
- ë°ì´í„° ì¶œì²˜: ì§ì ‘ì‘ì„± , êµë³´ë¬¸ê³ 

ë°ì´í„° ì˜ˆì‹œ

|**ì§ˆë¬¸**|ë‹µë³€|
|---|---|
|ë°°ì†¡ì€ ì–¼ë§ˆë‚˜ ê±¸ë¦¬ë‚˜ìš”?|ë³´í†µ ê²°ì œ ì™„ë£Œ í›„ 2~3ì¼ ì´ë‚´ì— ë°°ì†¡ë©ë‹ˆë‹¤. ì§€ì—­ì— ë”°ë¼ ì°¨ì´ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.|
|ì£¼ë¬¸í•œ ì±…ì´ ì•„ì§ ë„ì°©í•˜ì§€ ì•Šì•˜ì–´ìš”.|ë²ˆê±°ë¡œìš°ì‹œê² ì§€ë§Œ ì£¼ë¬¸ë²ˆí˜¸ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë°°ì†¡ ìƒíƒœë¥¼ í™•ì¸í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.|
|ê²°ì œ ìˆ˜ë‹¨ì—ëŠ” ë¬´ì—‡ì´ ìˆë‚˜ìš”?|ì‹ ìš©ì¹´ë“œ, ê³„ì¢Œì´ì²´, ì¹´ì¹´ì˜¤í˜ì´, ë„¤ì´ë²„í˜ì´ ë“±ì„ ì§€ì›í•©ë‹ˆë‹¤.|

|ì œëª©|ì‘ê°€|ë‚´ìš©|ì¥ë¥´|
|---|---|---|---|
|ë¹›ê³¼ ì‹¤|í•œê°•|ì—­ì‚¬ì  íŠ¸ë¼ìš°ë§ˆë¥¼ ì •ë©´ìœ¼ë¡œ ë§ˆì£¼í•˜ê³  ì¸ê°„ ì‚¶ì˜ ì—°ì•½í•¨ì„ ë“œëŸ¬ë‚´ëŠ” ê°•ë ¬í•˜ê³  ì‹œì ì¸ ì‚°ë¬¸â€ì´ë¼ëŠ” ì„ ì • ì´ìœ ì™€ í•¨ê»˜ 2024ë…„ ë…¸ë²¨ë¬¸í•™ìƒì„ ìˆ˜ìƒí•œ ì‘ê°€ í•œê°•ì˜ ì‹ ì‘ ã€ë¹›ê³¼ ì‹¤ã€(2025)ì´ ë¬¸í•™ê³¼ì§€ì„±ì‚¬ ì‚°ë¬¸ ì‹œë¦¬ì¦ˆ ã€ˆë¬¸ì§€ ì—í¬ë¦¬ã€‰ì˜ ì•„í™‰ë²ˆì§¸ ì±…ìœ¼ë¡œ ì¶œê°„ë˜ì—ˆë‹¤. ë…¸ë²¨ë¬¸í•™ìƒ ìˆ˜ìƒ ê°•ì—°ë¬¸ ã€Œë¹›ê³¼ ì‹¤ã€(2024)ì„ í¬í•¨í•´ ë¯¸ë°œí‘œ ì‹œì™€ ì‚°ë¬¸, ê·¸ë¦¬ê³  ì‘ê°€ê°€ ìì‹ ì˜ ì˜¨ì „í•œ ìµœì´ˆì˜ ì§‘ìœ¼ë¡œ â€˜ë¶í–¥ ë°©â€™ê³¼ â€˜ì •ì›â€™ì„ ì–»ê³ ì„œ ì¨ë‚¸ ì¼ê¸°ê¹Œì§€ ì´ ì—´ë‘ ê¼­ì§€ì˜ ê¸€ì´, ì—­ì‹œ ì‘ê°€ê°€ ê¸°ë¡í•œ ì‚¬ì§„ë“¤ê³¼ í•¨ê»˜ ë¬¶ì˜€ë‹¤. ì‚¼ì‹­ ë…„ ë„˜ê²Œ â€˜ì“°ëŠ” ì‚¬ëŒâ€™ì˜ ì •ì²´ì„±ìœ¼ë¡œ, â€œì„¸ê³„ëŠ” ì™œ ì´í† ë¡ í­ë ¥ì ì´ê³  ê³ í†µìŠ¤ëŸ¬ìš´ê°€? ë™ì‹œì— ì„¸ê³„ëŠ” ì–´ë–»ê²Œ ì´ë ‡ê²Œ ì•„ë¦„ë‹¤ìš´ê°€?â€ ì¤‘ëµ|ì‹œ/ì—ì„¸ì´|
|ë¶€ì˜ ì „ëµ ìˆ˜ì—…|í´ í¬ëŒìŠ¤í‚¤,|ã€Šë¶€ì˜ ì „ëµ ìˆ˜ì—…ã€‹ì€ í—¤ì§€í€ë“œì˜ ëŒ€ë¶€ì¸ ë ˆì´ ë‹¬ë¦¬ì˜¤ê°€ ì£¼ëª©í•œ ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ì˜ ìƒˆë¡œìš´ ììˆ˜ì„±ê°€ ì•„ì´ì½˜, í´ í¬ëŒìŠ¤í‚¤ì˜ ë¶€ì— ê´€í•œ ì˜ˆë¦¬í•˜ê³  ì‹¤ì „ì ì¸ ë‚´ìš©ì„ ë‹´ì€ ì±…ì´ë‹¤. ìš°ë¦¬ëŠ” ëª¨ë‘ ë¶€ë¥¼ ì›í•˜ì§€ë§Œ, ê·¸ê²ƒì€ ì–»ê¸° ì‰½ì§€ ì•Šë‹¤. í•˜ë£¨ê°€ ë‹¤ë¥´ê²Œ ë¹ ë¥´ê²Œ ë³€í™”í•˜ëŠ” ì„¸ê³„ëŠ” íˆ¬ìë¥¼ ë¶ˆí™•ì‹¤í•˜ê²Œ ë§Œë“¤ê³ , ëŠì„ì—†ì´ ë³€í•˜ëŠ” ìì‚°ì˜ ê°€ì¹˜ëŠ” ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•˜ê¸° í˜ë“¤ê²Œ ë§Œë“ ë‹¤. ì¤‘ëµ|ê²½ì œ/ê²½ì˜|
|2500ë…„ ë™ì•ˆ ì‚¬ë‘ë°›ì€ ì´ˆì—­ ë¶€ì²˜ì˜ ë§|ì½”ì´ì¼€ ë¥˜ë…¸ìŠ¤ì¼€|ì¸ë‚´ì‹¬ì„ ê°€ì ¸ë¼. ëª¨ë“  ê²ƒì€ ì ë‹¹í•œ ë•Œì— ê²°êµ­, ë„¤ê²Œ ì˜¬ í…Œë‹ˆ. ì–¸ì  ê°€ ë„ˆëŠ” ë„¤ê°€ ìˆì–´ì•¼ í•  ê³³ì—ì„œ ë„ˆì™€ í•¨ê»˜í•  ìš´ëª…ì¸ ì‚¬ëŒê³¼ ë„¤ê°€ í•´ì•¼ í•  ì¼ì„ í•˜ë©° ì‚´ê²Œ ë  ê²ƒì´ë‹¤. ã€Œë¶€ì²˜ã€ 2500ë…„ ë™ì•ˆ ì‚¬ëŒë“¤ì—ê²Œ ì‚¬ë‘ë°›ìœ¼ë©° íšŒìë˜ì–´ ì˜¨ ë¶€ì²˜ì˜ ë§ì„ ì½”ì´ì¼€ ë¥˜ë…¸ìŠ¤ì¼€ ìŠ¤ë‹˜ì´ í˜„ëŒ€ì–´ë¡œ ì¬í•´ì„í•´ ì±…ìœ¼ë¡œ ì¶œê°„í–ˆë‹¤.|ì¸ë¬¸|

## 4.1 êµ¬í˜„ ê²°ê³¼

# 5ì¥. í•œê³„ì 

- ê¸°ìˆ ì  í•œê³„ : ì˜¤íƒˆìê°€ í¬í•¨ëœ ì§ˆë¬¸ ì²˜ë¦¬ ë¯¸í¡, ì‘ë‹µ ë‚´ìš© ì˜¤ì—¼ ê°€ëŠ¥ì„± ì¡´ì¬
- ë¦¬ì†ŒìŠ¤ í•œê³„ : í¬ë¡¤ë§ ë° ì§ì ‘ ì‘ì„± ë°ì´í„°ì— ì˜ì¡´í•˜ì—¬ ë°ì´í„°ëŸ‰ì´ ì¶©ë¶„í•˜ì§€ ì•Šì„ ê°€ëŠ¥ì„±
- ê¸°ëŠ¥ì  í•œê³„ : ë™ì¼ ì§ˆë¬¸ì— ëŒ€í•´ ë‹¤ë¥¸ ë‹µë³€ì„ ì œê³µí•  ê°€ëŠ¥ì„± ì¡´ì¬, ì±… ì •ë³´ì™€ ì¼ë°˜ ê³ ê° ì‘ëŒ€ ë™ì‹œ ë‹µë³€ ë¶ˆê°€

# 6ì¥. ê°œì„ ë°©í–¥

- ê¸°ìˆ ì  í•œê³„ ê°œì„ 
    
    **ìì—°ì–´ ì²˜ë¦¬(NLP)ì™€ ì±… ê²€ìƒ‰ ëª¨ë¸ì„ ë¶„ë¦¬í•˜ì—¬ ìš´ì˜** â†’ ê³ ê° ì‘ëŒ€ ì •í™•ë„ ë° ì‘ë‹µ ì¼ê´€ì„±ì„ í–¥ìƒ, ì‘ë‹µ ì˜¤ì—¼ ê°€ëŠ¥ì„± ìµœì†Œí™”
    
- ë¦¬ì†ŒìŠ¤ í•œê³„ ê°œì„ 
    
    **ê¸°ì—… í™˜ê²½ì—ì„œëŠ” ì¶©ë¶„í•œ ë°ì´í„° í™•ë³´ ê°€ëŠ¥** â†’ ì‹¤ì œ ìš´ì˜ì—ì„œëŠ” ë°ì´í„° ë¶€ì¡± ë¬¸ì œê°€ í¬ì§€ ì•Šì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒ
    
- ê¸°ëŠ¥ì  í•œê³„ ê°œì„ 
    
    **í•™ìŠµ ê°€ì¤‘ì¹˜ ì¡°ì •ìœ¼ë¡œ ë‹µë³€ì˜ ì¼ê´€ì„±ì„ ìœ ì§€**
    
    **ì±… ì •ë³´ ê²€ìƒ‰ê³¼ ì¼ë°˜ ê³ ê° ì‘ëŒ€ ê¸°ëŠ¥ì„ ë¶„ë¦¬í•˜ë˜, ì´ë¯¸ì§€ ê²€ìƒ‰ ë° ìŒì„± ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ì—¬ ì„œë¹„ìŠ¤ í™•ì¥ ê°€ëŠ¥**
    

# 7ì¥. ê¸°ëŒ€íš¨ê³¼

<aside> ì •ëŸ‰ì  íš¨ê³¼

</aside>

**ì‘ë‹µ ì†ë„ í–¥ìƒ**

AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ CS ì§ì› ì±„ìš©ë³´ë‹¤ ì‘ë‹µì„± **ê°œì„ **

ê¸°ì¡´ ê³ ê° ì‘ëŒ€ ëŒ€ë¹„ **ì‹¤ì‹œê°„ ì‘ë‹µ ê°€ëŠ¥**, í‰ê·  ì‘ë‹µ ì‹œê°„ **1ì´ˆ ë¯¸ë§Œ**

**ê³ ê° ë¬¸ì˜ í•´ê²°ìœ¨ ì¦ê°€**

AI ì±—ë´‡ì„ í™œìš©í•˜ë©´ ë°˜ë³µ ì§ˆë¬¸ ìë™ ì‘ë‹µìœ¼ë¡œ **ê³ ê° ë¬¸ì˜ í•´ê²°ìœ¨ ìƒìŠ¹**

ë‹¨ìˆœ ë¬¸ì˜(ì±… ì¶”ì²œ, ê°€ê²© í™•ì¸ ë“±) ì‘ë‹µ ë†’ì€ ì‘ë‹µ ì„±ê³µë¥  **ìœ ì§€**

**ìš´ì˜ ë¹„ìš© ì ˆê°**

AI ëª¨ë¸ì´ ê¸°ë³¸ì ì¸ ê³ ê° ì‘ëŒ€ë¥¼ ì²˜ë¦¬í•˜ì—¬ **ìƒë‹´ì› ìš´ì˜ ë¹„ìš© ì ˆê° ê°€ëŠ¥**

ê³ ê° ì‘ëŒ€ ì¸ë ¥ ë¶€ë‹´ ì™„í™” â†’ AIê°€ ì²˜ë¦¬í•˜ëŠ” ë¬¸ì˜ëŸ‰ **ê¸°ì¡´ ëŒ€ë¹„ 50% ì¦ê°€, ì‘ë‹µ í€„ë¦¬í‹° ìƒìŠ¹**

<aside> ì •ì„±ì  íš¨ê³¼

</aside>

**ê³ ê° ë§Œì¡±ë„ í–¥ìƒ**

AI ì±—ë´‡ì´ ì‹¤ì‹œê°„ìœ¼ë¡œ ì‘ë‹µí•˜ì—¬ **ê³ ê°ì˜ ê¸°ë‹¤ë¦¼ ì—†ì´ ë¹ ë¥¸ ì •ë³´ ì œê³µ ê°€ëŠ¥**

ê°œì¸ ë§ì¶¤í˜• ì¶”ì²œ ê¸°ëŠ¥ìœ¼ë¡œ **ê³ ê°ì´ ì›í•˜ëŠ” ì±…ì„ ë” ì‰½ê²Œ ì°¾ì„ ìˆ˜ ìˆìŒ**

**ì‚¬ìš©ì ì ‘ê·¼ì„± í™•ëŒ€**

AI ì±—ë´‡ì´ 24ì‹œê°„ ìš´ì˜ë¨ìœ¼ë¡œì¨ **ì–¸ì œë“ ì§€ ê³ ê° ì‘ëŒ€ ê°€ëŠ¥**

ê°€ë³ê³  í”„ë¼ì´ë¹—í•œ ìƒë‹´ìœ¼ë¡œ ì ‘ê·¼ì„± í™•ëŒ€

ìŒì„±/ì´ë¯¸ì§€ ê²€ìƒ‰ ê¸°ëŠ¥ ì¶”ê°€ë¡œ **ê¸°ì¡´ í…ìŠ¤íŠ¸ ê²€ìƒ‰ë³´ë‹¤ ì§ê´€ì ì¸ ì ‘ê·¼ ì œê³µ**

**ì„œë¹„ìŠ¤ ì‹ ë¢°ë„ ê°•í™”**

ì°©ì˜¤ë¡œ ì¸í•œ ì‹¤ìˆ˜ ì—†ì´ ì¼ê´€ëœ ì‘ë‹µì„ ì œê³µí•˜ì—¬ **ê³ ê°ì´ ì±—ë´‡ì„ ì‹ ë¢°í•  ê°€ëŠ¥ì„±ì´ ë†’ì•„ì§**

